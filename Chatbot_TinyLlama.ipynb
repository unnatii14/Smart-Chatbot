{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "source": ["# Smart Chatbot: A Hybrid Chatbot with Knowledge Retrieval"], "metadata": {"id": "QXgIJyOwsIT5"}}, {"cell_type": "markdown", "source": ["## Cell 1: Install Required Libraries\n", "Installs Hugging Face Transformers for LLMs, Gradio for web UI, Sentence-Transformers for embeddings, and FAISS for vector search (RAG)."], "metadata": {"id": "woVivUXssQh3"}}, {"cell_type": "code", "source": ["!pip install -q transformers accelerate gradio sentence-transformers faiss-cpu"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "-CyncOnFsVWy", "outputId": "6629cb9b-c11d-4b55-d070-a8e6133cfefe"}, "execution_count": 1, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h"]}]}, {"cell_type": "markdown", "source": ["\n", "## Cell 2: Import Modules\n", "Import all necessary libraries for transformers, embeddings, FAISS, Gradio UI, and PyTorch"], "metadata": {"id": "YJrwvyEgsZ3y"}}, {"cell_type": "code", "source": ["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n", "from sentence_transformers import SentenceTransformer\n", "import faiss\n", "import gradio as gr\n", "import torch\n", "import numpy as np"], "metadata": {"id": "TlKkR5Xcsld4"}, "execution_count": 2, "outputs": []}, {"cell_type": "markdown", "source": ["## Cell 3: Load Language Model and tokenizer\n", "This model handles user prompts and generates replies."], "metadata": {"id": "_hRlfOaLtFwb"}}, {"cell_type": "code", "source": ["model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n", "tokenizer = AutoTokenizer.from_pretrained(model_id)\n", "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16)\n", "chat_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 382, "referenced_widgets": ["44a6cdd32e054821bb4404e8751fe846", "357a40832c8c4b7daad52ea6f493664e", "6bb1daedc0fe454baa0d960949371c2b", "5a0559e8c108402594aae56df7b3d16a", "d88fdf78f77d4fa7b8c8abf28d0f4862", "1343710253d54866be4968aea7fc0d53", "8de94a7e8061407782528496c8a81331", "0c1d605a84df4184ada1e71f1efe3188", "1af56c449786463ab03797a784a54f35", "7c74b8b2073a45ca8993d7dbd4761fb0", "69ab98bc317d4d7b9dfa2a500aa0be2d", "991af659362b40d4a9ea05f4ceec3323", "7acfd4e405e04befab838cf182b00211", "002c3ded06224832866b77dcba47cc3c", "bd398db0bde0447f9010709a68e4abfa", "3fe264592d39453ba397e732163e9ef7", "08b0070abe7f455b975939e8b15980f1", "7bd70339020a4932a0283144f6d2bdc1", "75d11bf2f1734b00b44a9f5afd144822", "302c10bf38234e858af96e5bb5c21853", "5e7124d5044e4bf0ba54acb6ea2aff5a", "4870eb3bc5c248dea7455efd06d7c99c", "d87abf888e904d3f9b34f4d30ab3082a", "697f6497d84f447fa676d2af42c9e947", "8f7dcf59061747bfaf978b6129ac3f89", "1b298120fbc94f50ac382fe835dbe91b", "f3757c384f5b4341ad47fbfb5b655ab9", "32af6fe4fcd04f56a85d35a2c2faeab6", "77f6bbaef9d74e999f43cf29ec34a810", "b7c72097345848f7ad9b32f1b56b906e", "9f8e1c2e85d04acba7cc08889d5f090c", "b522fc1915ac4dcdaef8f53c079ff08b", "9d03e1a6344c4232ae1b8cddc0b7fa4e", "2abc64c214584d56807e54291c4476f2", "4e47d3f0eef44be8a4831d4e7cb5c3d0", "15ea0518fc584d2e85eeb8c421119598", "5a5f0ef32ccc4357946de73592fe69a3", "7f00a35f8a8d49caa33737635b85e663", "4ab4771902034c6a94783f94109a0ada", "4bcf7ff63b604871ba9ac1a2d695d5de", "ef2688afb506468c948032f623cb028a", "e72eadf0cb084ed491cb25a24fd8b51d", "64617361f1564cd18adfc57479c0516e", "0ef99e477acf4ca38dc3a8a7cb9af590", "dfae92d767134c38b7ab9e52ac54f0cc", "b858823e6a994578a68d78aff7e0ea0c", "8e9a82a8b4bf4d9ba6dc12aea689bcdd", "67017e8f121a4cbb99f8e8f84c18c457", "dff1f21c45964cb4873ce8501c207dfd", "85c5f8ce80ea4c03b1258f27aa8e8ab3", "1f5e5ca946ae4aea883cb3a7046ff203", "f8949ccb61844ad4bbb38a8dc6135781", "4912cf3113684d5dab690c5b1215d1db", "bc212bc721b448f3a40f3741aa8390e4", "9e7e49eedd87424694ecb1e1ffcb28a7", "bb182687bcae42aabe33214f7011a614", "540f3a9819a14a5a94697bf8df2b0cf2", "0df052ce807a4c8386ca42bd836dc643", "259b446901f742aa9ca2a9ced5f7f617", "34d729974bdf445ca9549660303e7a4e", "34ec045f67cb44b983bc3b635302f950", "8892abbfad9546e297ed9eea01310c5b", "0b65bde818f8491aaa77ed4475518f73", "aed8e0040c774fc49782f3851ff163e8", "4c18553e621d402fbfa6f2b813d3ad5d", "536a5f4b0f5e416c9e8ffee45c798c24", "3d57ef4e30054bf0a737005cff00448c", "cfbc9a0740d1465aa4354ed15a0426be", "e944fb098e1e4251a00ae61669561a2a", "ca29a4066ae64bb1a648991058780b3b", "73ca9641409b42c9a47a317250b277d6", "ac993cfa9a3a42f5af0bc9d9390931a0", "77d43a45d83746b2851c31e54df3b5f0", "e7e1c32f33e641bfb129576b6a930276", "0223c4fed02f4b708174f311beb2e702", "44bafbd8f08f407c84e531129167ffba", "5233619f404548fc925c80865c01a5e7"]}, "id": "f0PPT8ZmtaFS", "outputId": "463be40b-1ee9-4951-f2d6-f7ae429616fc"}, "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n", "The secret `HF_TOKEN` does not exist in your Colab secrets.\n", "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n", "You will be able to reuse this secret in all of your notebooks.\n", "Please note that authentication is recommended but still optional to access public models or datasets.\n", "  warnings.warn(\n"]}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "44a6cdd32e054821bb4404e8751fe846"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "991af659362b40d4a9ea05f4ceec3323"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d87abf888e904d3f9b34f4d30ab3082a"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2abc64c214584d56807e54291c4476f2"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "dfae92d767134c38b7ab9e52ac54f0cc"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bb182687bcae42aabe33214f7011a614"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3d57ef4e30054bf0a737005cff00448c"}}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["Device set to use cuda:0\n"]}]}, {"cell_type": "markdown", "source": ["## Cell 4: Setup RAG - Load Embedding Model & Vector Store\n", "\n", "Load embedding model and create FAISS index to store and search document embeddings. Also initialize a list to keep original texts."], "metadata": {"id": "4IgE43SftU1t"}}, {"cell_type": "code", "source": ["embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n", "index = faiss.IndexFlatL2(384)\n", "doc_texts = []"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 369, "referenced_widgets": ["4c82bc4e2847476289adc099dd72a957", "2552e90e14e94a90a2f50cbab3f6b45b", "8114ca94cf8b4b29866cba74aa53f384", "3b661ae749544805854eb5e249a75a05", "f2b6e82cece1413c8457749c70ad9ecc", "4b1c1168c74b4213bf883b954c202b46", "48910eec4e474e50b00c2dac2d11b0c1", "46c0f05402a04de1b9833097b672a5e7", "ce681744fcb94a159a6d892c2233fe20", "fde154a0a996404294c369db56c42371", "3b51fbc9ba0e49b2b7301806b9ca01b5", "f152734a81ff447fa75dd5eccb20a2b4", "ddcffbf068484afba393cdc53bbf1284", "0a36393ac1dc4369a40937b3b3502d94", "b82d9b1d66b74fbcab28179bbd48d5d7", "51880b51d38b432aa830361c5a12927b", "6e963e8cd9a24c06afbc1663814f16d5", "c6ccffa3655a4992a5c603d4eac0d573", "03c5baed21684fe6a66ce6277e68a719", "92568548d7fa49d4abc005bdeb4f0122", "07fc5bac0cea4b4991ba810387dee1a4", "5e9fe3bbf3674b00a949ee7f13a3423d", "795e823e35b64c55a9bd33d1ccc65ca3", "4e0a2ff824fa44228e60344a770ee8f5", "719a5cdcb0ce4bcd8868ad77843cb3d5", "7a1b6d9c8d7a418fb7e6370ae1c46832", "8b99cf72ccb7408a9852e16c1dc9063d", "38bf9c74baba4ac28ca19f24135d0ddd", "1cdfbc89397a41b2aad4e08c59e3dcd1", "c9fead788f5d4588a402f636838ae276", "4a84a4c50d8c4b7d8728dfb364192b61", "e00ae10e7bbf48b09a888a94f17c56a9", "761fc16292794bb1ba0c102c66cb8c3b", "e5c4685750e24f1f90f35a7a3760c912", "a537968f3608433eb7799833d9516b12", "f01b0b6e865d482ca800529f2a78b349", "daa5e9b04d294dd58c0a4b84bf1272fa", "f577618781da4bca99268de1e8bae6cf", "d47b258060b54803b91113e9ebd95132", "25d7bfdbc8684af5a1ec5e3d265c5dbf", "7823086fa2704220ae933155781c508e", "8c3ab6b3611b4691bf24aff513d272e6", "a81495713f4a4b70a138d50f4da15336", "bb592ac095fd47f3a8417196f5ac55a7", "b2ff5fc8d4744fb0948d011ef28bf18c", "281a8a1ce1f5488ca521cc379ca568fb", "13a3b9e1e0f84ce196234e4429e6ab74", "564d40c23ff14a149b1ffd4654309fee", "2cba0e68b1ba4ef8bd34ce98d4243f93", "e01864207ea14de9b95cf1e7f4daed98", "2003233230ab45fc887eef97ba3808d8", "8b143bfb53ba4655bc6e2e2c0c74e415", "f77cdff1e0c34e20be66c0709bb33f7a", "d83b0fd118a845018bfedc05f1c27a69", "44edb5147053455eb28a32dd4311599f", "82e722c1eee640e08f0556a7c69e6d06", "b608dce9b7474a43aabd45339ca5b740", "c75934326fce44c5a7deacd5ffeeee3f", "8620cad0c8324df0b5425ae475919046", "1944281888c44539879f96b9919b03fc", "2d438570d61449be959db34ca236edd3", "40189d04f0cd4ec394c96364b860c4a2", "a05bffff809a432897409b111aadd367", "9f86e845af7b4e8d90e47086bd9f0717", "dd2425d11dc74dddaabd969da396e2fc", "1b01ecf2e05c4303a519c8c80fe7c957", "76f5440a09e04c52b32b828db8a80cc6", "b29d5bfbe7434ac39b958d34d6a7aaf9", "3775a58c201f4a25b94ffbe81ea58a02", "109ac0f285fd49808dafcb315410c107", "89d438a046824628bbc51eafc1843dec", "66c384d65ac0494fb51219ad77da4e0c", "8fb80c0205c54112a9045bd85a43a2ec", "75da2b4084db4ad88f7fcdbcdaaa8773", "b21f9b5991124b5ca4e8533de622246d", "b4bcc64ec09f40578d2dd012aa34655a", "5b50a1ed8f704e008ec7a2b546be7a9d", "b1228a21284b4395b1a8ce35999d74c3", "6c3becb4b82749bb9a8900c7d9880de6", "1e6c628a7c854a7aa01d6a282f4e399d", "4290cbfcf9bb403482e1a8e45c28fadb", "60d19b0216184c7c92b3898f91729ee6", "58c9a347884149d68269237143e10a63", "86b7ce83ca424d5a89ec5f3baa7c4c7a", "fcb315daa4be4dc98d0fdd85729c8f96", "f0663363a3054b53aaed52bd2d745270", "6dbe8c19e1ce4260ab4b8bdb0e9ca342", "a4e7c881ec404b7c86ca5a9f8872411d", "591503178392471e9dfd803bee4202fd", "644f5b1bf6824dee92e08777cdccc4c5", "633306a9bf4e4f76a99647fe2c6a17fd", "e2cb30990df147ba89540f09b856fb62", "ea8041f31f5c4852a9b94266034adea8", "78f113cee3e74ba69b02983191b511ca", "c341d0190c4e4b5db541d1298085322a", "1b5898f80708429c9eada9bef3b2d3c0", "fe5ddf81fe2646bfba6140fccdbabede", "67ee3ea48a5f4497a32fabb85b79f36c", "4851f151276c4bf4a6d8d02032677879", "befd911fa6cc4413b10750719c9a2bef", "713521efa38e415ba906adb65ef36eea", "b69453d332b64595a8e2ce7e12bcac0b", "e11aa3fa38284293ae7382fd719268f6", "b96d8c0df85d480b9385f1c828ffa145", "f97e9ab9c77048e9a4d5b14c59661273", "b8e07fc38d63466eaf50d8958f8de5a5", "ccac13eeeeed44fca64b33bc6e9787f9", "9ab157b34502430aadb0bde7bd066bdc", "6e107fdb98c540b1b7176c0361107dbe", "619e30591e1943d28bcab3aabfce6337", "06e422a01ec44ace829825de44dc77cd", "0748f1db3b47443abe6471eb9040d399", "20e8eeffde824e3fb0495c8b948b87a7", "e42dd539a3ad48f4b3c8a2994041902d", "77ea4cec9a854ca694414686698db783", "cfbdb8190f1b436a9397aa5ed78e1c39", "6436982809fd49f49fca17133ac1562c", "5446f5ac24964bf6875f5d54aafd1097", "9c3bd0a96a3b4de2bcf8491be278a5f0", "0c2401bf29ac4df899be81c5db21e5ed", "19c9461bfd334db5ba35fb4ecba9a9f0"]}, "id": "YC7OR8K4to3n", "outputId": "b50147f6-f016-4547-eaca-8f8aa14d30bc"}, "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": ["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4c82bc4e2847476289adc099dd72a957"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f152734a81ff447fa75dd5eccb20a2b4"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "795e823e35b64c55a9bd33d1ccc65ca3"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e5c4685750e24f1f90f35a7a3760c912"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b2ff5fc8d4744fb0948d011ef28bf18c"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "82e722c1eee640e08f0556a7c69e6d06"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "76f5440a09e04c52b32b828db8a80cc6"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b1228a21284b4395b1a8ce35999d74c3"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "591503178392471e9dfd803bee4202fd"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "befd911fa6cc4413b10750719c9a2bef"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "06e422a01ec44ace829825de44dc77cd"}}, "metadata": {}}]}, {"cell_type": "markdown", "source": ["## Cell 5: Function to Upload and Process Documents\n", "This function takes a text document, embeds it using the SentenceTransformer, and stores it in FAISS."], "metadata": {"id": "EP82j6MPso8-"}}, {"cell_type": "code", "source": ["def add_document(text):\n", "    global doc_texts\n", "    doc_texts.append(text)\n", "    embedding = embedding_model.encode([text])\n", "    index.add(embedding)\n", "    return"], "metadata": {"id": "EoNdx5MjtxiO"}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": ["This function resets both the document list and FAISS index."], "metadata": {"id": "0xZLLzdO6U4B"}}, {"cell_type": "code", "source": ["def clear_documents():\n", "    global doc_texts, index\n", "    doc_texts = []\n", "    index = faiss.IndexFlatL2(384)\n", "    return"], "metadata": {"id": "ud-F58gr6Tye"}, "execution_count": 6, "outputs": []}, {"cell_type": "markdown", "source": ["## Cell 6: RAG-based Chat Function\n", "Main function to handle user input. If documents are available, it retrieves the most relevant one.\n", "Based on similarity, it decides whether to include the document in the prompt."], "metadata": {"id": "KAXOCT-ct4lh"}}, {"cell_type": "code", "source": ["def chat_with_model(message, history):\n", "    if len(doc_texts) > 0 and index.ntotal > 0:\n", "        query_embedding = embedding_model.encode([message])\n", "        D, I = index.search(query_embedding, k=1)\n", "\n", "        # FAISS returns squared L2 distance \u2014 convert to similarity\n", "        distance = D[0][0]\n", "        similarity = 1 / (1 + distance)  # normalize (pseudo-cosine)\n", "\n", "        if similarity > 0.6:\n", "            context = doc_texts[I[0][0]]\n", "            prompt = f\"<|user|>\\nContext: {context}\\nQuestion: {message}\\n<|assistant|>\\n\"\n", "        else:\n", "            context = None\n", "            prompt = f\"<|user|>\\n{message}\\n<|assistant|>\\n\"\n", "    else:\n", "        prompt = f\"<|user|>\\n{message}\\n<|assistant|>\\n\"\n", "\n", "    # Generate\n", "    response = chat_pipeline(prompt, max_new_tokens=200, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n", "    reply = response.split(\"<|assistant|>\")[-1].strip()\n", "\n", "    history.append((f\"You: {message}\", f\"Bot: {reply}\"))\n", "    return history, history"], "metadata": {"id": "7DrdHDY0uBhX"}, "execution_count": 7, "outputs": []}, {"cell_type": "markdown", "source": ["## Cell 7: Gradio UI for Chatbot\n", "Use Gradio Blocks to create a simple web interface where users can upload text and chat with the bot."], "metadata": {"id": "G6YqfXmxuEiH"}}, {"cell_type": "code", "source": ["# UI with Gradio\n", "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n", "    gr.Markdown(\"# \ud83e\udd16 Smart Chatbot \\nAsk questions or upload documents!\")\n", "    chatbot = gr.Chatbot(label=\"Chat History\")\n", "    msg = gr.Textbox(label=\"Your Message\", placeholder=\"Ask me anything!\", lines=1)\n", "    upload = gr.Textbox(label=\"Paste document here (optional)\", lines=5)\n", "    state = gr.State([])\n", "\n", "    upload.submit(lambda doc: add_document(doc), upload, upload)\n", "    clear_btn = gr.Button(\"\ud83e\uddf9 Clear All Documents\")\n", "    clear_btn.click(fn=clear_documents, outputs=upload)\n", "    msg.submit(chat_with_model, [msg, state], [chatbot, state])\n", "\n", "demo.launch(share=True)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 646}, "id": "2UHYfPF1uMiQ", "outputId": "436440e9-23df-44bf-bd6d-728385037b28"}, "execution_count": 8, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["<ipython-input-8-eb9bfda448bd>:4: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n", "  chatbot = gr.Chatbot(label=\"Chat History\")\n"]}, {"output_type": "stream", "name": "stdout", "text": ["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n", "* Running on public URL: https://2f883bf20a9a5bd60b.gradio.live\n", "\n", "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["<div><iframe src=\"https://2f883bf20a9a5bd60b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]}, "metadata": {}}, {"output_type": "execute_result", "data": {"text/plain": []}, "metadata": {}, "execution_count": 8}]}, {"cell_type": "code", "source": [], "metadata": {"id": "5aNkgIB787Bb"}, "execution_count": 8, "outputs": []}]}